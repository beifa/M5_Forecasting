{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drop_features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1T_gaQvq-D2bzX21AxCVrjgPpbvjGH4Cf",
      "authorship_tag": "ABX9TyOezR74KAbSokVh0oBCF4jc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beifa/M5_Forecasting/blob/master/drop_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wTO6DB8Z-Sj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "48b47d1f-14ce-4fbe-fbd2-629afe0f68aa"
      },
      "source": [
        "!pip install lightgbm -U"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lightgbm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.14.1)\n",
            "Installing collected packages: lightgbm\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed lightgbm-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjU4ggFFqrl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37dcbb2a-79d6-4a24-cb7e-9c41addb055a"
      },
      "source": [
        "import gc\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PATH =  '/content/drive/My Drive/M5_Forecasting/data/'\n",
        "PATH_MODEL = '/content/drive/My Drive/M5_Forecasting/kaggle_kernels/models/'\n",
        "\n",
        "SEED = 13\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "lgb.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxD7L7XyZnlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahHexk_uq7El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VER = 1\n",
        "\n",
        "lgb_params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse'    \n",
        "    'verbose': -1,\n",
        "    'n_estimators': 1000,\n",
        "    }\n",
        "\n",
        "lgb_params['seed'] = SEED              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzSGWmkyq4Us",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title read_data not for share\n",
        "\n",
        "def read_data(store, start = 0):\n",
        "  \"\"\"\n",
        "  read data by store_id\n",
        "  \"\"\"\n",
        "  mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
        "                   'enc_dept_id_mean','enc_dept_id_std',\n",
        "                   'enc_item_id_mean','enc_item_id_std'] \n",
        "\n",
        "  remove_features = ['id','state_id','store_id',\n",
        "                   'date','wm_yr_wk','d','sales']\n",
        "\n",
        "  df = pd.concat([\n",
        "                pd.read_pickle(PATH + 'grid_part_1.pkl'),\n",
        "                pd.read_pickle(PATH + 'grid_part_2.pkl').iloc[:, 2:],\n",
        "                pd.read_pickle(PATH + 'grid_part_3.pkl').iloc[:, 2:]],\n",
        "                axis =1\n",
        "                )\n",
        "  df= df[df.store_id == store]\n",
        "  gc.collect()\n",
        "  encode = pd.read_pickle(PATH + 'mean_encoding_df.pkl').iloc[:, 2:]\n",
        "  encode = encode[encode.index.isin(df.index)]\n",
        "  df = pd.concat([df, encode], axis=1)\n",
        "  del encode\n",
        "  gc.collect()\n",
        "  \n",
        "  lags = pd.read_pickle(PATH + 'lags_df_28.pkl').iloc[:, 3:]\n",
        "  lags = lags[lags.index.isin(df.index)]\n",
        "  df = pd.concat([df, lags], axis=1)\n",
        "  del lags\n",
        "  gc.collect()\n",
        "\n",
        "  #new add stocks\n",
        "  stocks = pd.read_pickle(PATH + \"wmt_stocks_CloseVolumeAdj.pkl\")\n",
        "  stocks = stocks[stocks.index.isin(df.index)]\n",
        "  df = pd.concat([df, stocks], axis=1)\n",
        "  del stocks\n",
        "  gc.collect()\n",
        "\n",
        "  \n",
        "  features = [col for col in list(df) if col not in remove_features]\n",
        "  df = df[['id','d','sales']+features]\n",
        "\n",
        "  #skip row\n",
        "  df = df[df.d >= start].reset_index(drop=True)\n",
        "  return df, features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5YLY2X5lxzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(store, start = 0):\n",
        "\n",
        "    #тут убираем  почему разбиваем\n",
        "    #STORES&DEPT\n",
        "    remove_features = [\n",
        "                       'id',                        \n",
        "                       'date',\n",
        "                       'wm_yr_wk',\n",
        "                       'd',\n",
        "                       'sales',\n",
        "\n",
        "                       'store_id',\n",
        "                       'state_id',\n",
        "                       \n",
        "                       ]\n",
        "\n",
        "    \n",
        "    df = pd.concat([\n",
        "                pd.read_pickle('grid_part_1.pkl'),\n",
        "                pd.read_pickle('grid_part_2.pkl').iloc[:, 2:],\n",
        "                pd.read_pickle('grid_part_3.pkl').iloc[:, 2:]],\n",
        "                axis =1)\n",
        "    df= df[df.store_id == store]  \n",
        "    gc.collect()\n",
        "    \n",
        "   \n",
        "    lags = pd.read_pickle('lags_df_default28.pkl').iloc[:, 3:]\n",
        "    lags = lags[lags.index.isin(df.index)]\n",
        "    df = pd.concat([df, lags], axis=1)\n",
        "    del lags\n",
        "    gc.collect()\n",
        "    \n",
        "    encode = pd.read_pickle(PATH + 'mean_encoding_df.pkl').iloc[:, 2:]\n",
        "    encode = encode[encode.index.isin(df.index)]\n",
        "    df = pd.concat([df, encode], axis=1)\n",
        "    del encode\n",
        "    gc.collect()\n",
        "    \n",
        "    #new add stocks\n",
        "    stocks = pd.read_pickle(\"wmt_stocks_CloseVolumeAdj.pkl\")\n",
        "    stocks = stocks[stocks.index.isin(df.index)]\n",
        "    df = pd.concat([df, stocks], axis=1)\n",
        "    del stocks\n",
        "    gc.collect()\n",
        "    \n",
        "    #new add ewm, exp\n",
        "    ewm = pd.read_pickle(PATH + \"lags_ewm_exp.pkl\").iloc[:, 2:]\n",
        "    ewm = ewm[ewm.index.isin(df.index)]\n",
        "    df = pd.concat([df, ewm], axis=1)\n",
        "    del ewm\n",
        "    gc.collect()\n",
        "\n",
        "    df_16 = pd.read_pickle('df_16.pkl')\n",
        "    df_16 = df_16[df_16.index.isin(df.index)]\n",
        "    df = pd.concat([df, df_16], axis=1)\n",
        "    del df_16\n",
        "    gc.collect()\n",
        "\n",
        "    df_16_stat = pd.read_pickle('df_16_stat.pkl')\n",
        "    df_16_stat = df_16_stat[df_16_stat.index.isin(df.index)]\n",
        "    df = pd.concat([df, df_16_stat], axis=1)\n",
        "    del df_16_stat\n",
        "    gc.collect()\n",
        "\n",
        "    df_16_prob = pd.read_pickle('df_16_prob.pkl')\n",
        "    df_16_prob = df_16_prob[df_16_prob.index.isin(df.index)]\n",
        "    df = pd.concat([df, df_16_prob], axis=1)\n",
        "    del df_16_prob\n",
        "    gc.collect()\n",
        "\n",
        "    \n",
        "    features = [col for col in list(df) if col not in remove_features]\n",
        "    df = df[['id','d','sales']+features]\n",
        "    \n",
        "    #skip row\n",
        "    df = df[df.d >= start].reset_index(drop=True)\n",
        "    return df, features\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzRHNozRrOH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4ef56ba-4178-491c-af88-4cb57d4b1a65"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRL6DX1aw2EL",
        "colab_type": "text"
      },
      "source": [
        "subsample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wqqePxgwcOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#subsample for test\n",
        "store = 'CA_4'\n",
        "\n",
        "df, features = read_data(store, start = 0) #~800Mb, #subsamp_df.info()#48Mb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y3y5Hs0YyCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #'1,2,3'.split(',', maxsplit=1)\n",
        "# 'CA_2 TX_3 WI_1 CA_4'.split(' ', maxsplit= 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Anh58QxysE",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title train_subsample\n",
        "\n",
        "def train_subsamp(df, features):\n",
        "  \"\"\"\n",
        "  make for test, and make viz features  \n",
        "  \"\"\"\n",
        "\n",
        "  train_mask = df.d <= 1913\n",
        "  val_mask = (df.d <= 1913) & (df.d > (1913-28))\n",
        "  \n",
        "  train_data = lgb.Dataset(df[train_mask][features], \n",
        "                        label=df[train_mask]['sales'])\n",
        "  train_data.save_binary('train_data.bin')\n",
        "  train_data = lgb.Dataset('train_data.bin')\n",
        "  val_data = lgb.Dataset(df[val_mask][features], \n",
        "                      label=df[val_mask]['sales'])  \n",
        "  del df\n",
        "  gc.collect()\n",
        "  print('Start train lgbm')\n",
        "  estimator = lgb.train(lgb_params,\n",
        "                        train_data,\n",
        "                        valid_sets = [val_data],\n",
        "                        verbose_eval = 100,\n",
        "                        )\n",
        "  !rm '/content/train_data.bin'\n",
        "  del train_data, val_data#, estimator\n",
        "\n",
        "  gc.collect()\n",
        "  print('Ends') \n",
        "  return estimator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3dZ5bdt51J9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #CA_1\n",
        "# bad = ['enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean',\n",
        "#        'enc_dept_id_std', 'enc_state_id_cat_id_mean',\n",
        "#        'enc_state_id_cat_id_std', 'enc_state_id_dept_id_mean',\n",
        "#        'enc_state_id_dept_id_std', 'enc_store_id_cat_id_mean',\n",
        "#        'enc_store_id_cat_id_std', 'enc_store_id_dept_id_mean',\n",
        "#        'enc_store_id_dept_id_std']\n",
        "\n",
        "# bad_2 = ['price_momentum', 'event_name_2', 'event_type_2']\n",
        "# features_01  = [f for f in features if f not in bad+bad_2]\n",
        "\n",
        "# #TX_2\n",
        "# bad_3 = ['price_momentum', 'event_name_2', 'event_type_2']\n",
        "# bad_4 = ['cat_id', 'event_type_1', 'enc_dept_id_mean', 'enc_dept_id_std',\n",
        "#        'enc_state_id_cat_id_mean', 'enc_state_id_cat_id_std',\n",
        "#        'enc_state_id_dept_id_mean', 'enc_state_id_dept_id_std',\n",
        "#        'enc_store_id_dept_id_mean', 'enc_store_id_dept_id_std']\n",
        "# features  = [f for f in features if f not in bad+bad_2]\n",
        "# #wi_3\n",
        "# bad_5 = ['price_momentum', 'event_name_2', 'event_type_2']\n",
        "# bad_6 = ['cat_id', 'enc_dept_id_mean', 'enc_dept_id_std',\n",
        "#        'enc_state_id_dept_id_mean', 'enc_state_id_dept_id_std',\n",
        "#        'enc_store_id_dept_id_mean', 'enc_store_id_dept_id_std']\n",
        "\n",
        "# #not sub\n",
        "# bad_7 = ['cat_id', 'price_nunique', 'price_momentum', 'price_momentum_y',\n",
        "#        'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
        "#        'snap_CA', 'snap_TX', 'snap_WI', 'quarter', 'weekend',\n",
        "#        'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean',\n",
        "#        'enc_dept_id_std', 'enc_state_id_cat_id_mean',\n",
        "#        'enc_state_id_cat_id_std', 'enc_state_id_dept_id_mean',\n",
        "#        'enc_state_id_dept_id_std', 'enc_store_id_cat_id_mean',\n",
        "#        'enc_store_id_cat_id_std', 'enc_store_id_dept_id_mean',\n",
        "#        'enc_store_id_dept_id_std', 'num_lags28', 'num_lags29', 'num_lags30',\n",
        "#        'num_lags31', 'num_lags32', 'num_lags33', 'num_lags34', 'num_lags35',\n",
        "#        'num_lags36', 'num_lags37', 'num_lags38', 'num_lags39', 'num_lags40',\n",
        "#        'num_lags41', 'num_lags42', 'rolling_num_7_mean', 'rolling_num_14_mean',\n",
        "#        'num_lags_30_roll_7', 'num_lags_30_roll_14']\n",
        "\n",
        "# bads = bad +bad_2+bad_3+bad_4+bad_5+bad_6 + bad_7\n",
        "#to drops maybe not drop cat_id\n",
        "# 'cat_id'\n",
        "\n",
        "# 'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean',\n",
        "# 'enc_dept_id_std', 'enc_state_id_cat_id_mean', 'enc_state_id_cat_id_std',\n",
        "# 'enc_state_id_dept_id_mean', 'enc_state_id_dept_id_std', 'enc_store_id_cat_id_mean',\n",
        "# 'enc_store_id_cat_id_std', 'enc_store_id_dept_id_mean', 'enc_store_id_dept_id_std'\n",
        "\n",
        "# 'event_name_2', 'event_type_1', 'event_type_2'\n",
        "\n",
        "# 'price_momentum'\n",
        "################################################DROP##########################################\n",
        "# #CA_4\n",
        "# bad = ['cat_id', 'weekend', 'enc_dept_id_mean_item_id',\n",
        "#        'enc_dept_id_std_item_id', 'enc_state_id_dept_id_mean_item_id',\n",
        "#        'enc_state_id_dept_id_std_item_id', 'enc_store_id_dept_id_mean_item_id',\n",
        "#        'enc_store_id_dept_id_std_item_id', 'enc_state_id_mean',\n",
        "#        'enc_state_id_std', 'enc_store_id_mean', 'enc_store_id_std',\n",
        "#        'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean',\n",
        "#        'enc_dept_id_std']\n",
        "\n",
        "# #TX_1\n",
        "# bad_2 = ['cat_id', 'price_momentum', 'event_type_1', 'event_name_2',\n",
        "#        'event_type_2', 'weekend', 'enc_dept_id_mean_item_id',\n",
        "#        'enc_dept_id_std_item_id', 'enc_state_id_cat_id_mean_item_id',\n",
        "#        'enc_state_id_cat_id_std_item_id', 'enc_state_id_dept_id_mean_item_id',\n",
        "#        'enc_state_id_dept_id_std_item_id', 'enc_store_id_cat_id_mean_item_id',\n",
        "#        'enc_store_id_cat_id_std_item_id', 'enc_store_id_dept_id_mean_item_id',\n",
        "#        'enc_store_id_dept_id_std_item_id', 'enc_state_id_mean',\n",
        "#        'enc_state_id_std', 'enc_store_id_mean', 'enc_store_id_std',\n",
        "#        'enc_cat_id_mean', 'enc_cat_id_std', 'enc_dept_id_mean',\n",
        "#        'enc_dept_id_std']\n",
        "# #WI_1\n",
        "# bad_3 = ['cat_id', 'price_momentum', 'event_type_1', 'event_name_2',\n",
        "#        'event_type_2', 'enc_dept_id_mean_item_id', 'enc_dept_id_std_item_id',\n",
        "#        'enc_store_id_cat_id_mean_item_id', 'enc_store_id_cat_id_std_item_id',\n",
        "#        'enc_store_id_dept_id_mean_item_id', 'enc_store_id_dept_id_std_item_id',\n",
        "#        'enc_state_id_mean', 'enc_state_id_std', 'enc_store_id_mean',\n",
        "#        'enc_store_id_std', 'enc_cat_id_mean', 'enc_cat_id_std',\n",
        "#        'enc_dept_id_mean', 'enc_dept_id_std']\n",
        "# #no\n",
        "\n",
        "# bad_4 = ['cat_id', 'price_momentum', 'event_type_1', 'event_name_2',\n",
        "#        'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'weekend',\n",
        "#        'enc_dept_id_mean_item_id', 'enc_dept_id_std_item_id',\n",
        "#        'enc_state_id_dept_id_mean_item_id', 'enc_state_id_dept_id_std_item_id',\n",
        "#        'enc_store_id_dept_id_mean_item_id', 'enc_store_id_dept_id_std_item_id',\n",
        "#        'enc_state_id_mean', 'enc_state_id_std', 'enc_store_id_mean',\n",
        "#        'enc_store_id_std', 'enc_cat_id_mean', 'enc_cat_id_std',\n",
        "#        'enc_dept_id_std']\n",
        "\n",
        "# bads = bad + bad_2+ bad_3+bad_4\n",
        "#############################################DROP###########################################\n",
        "# #CA_2\n",
        "# bad = ['cat_id', 'price_nunique', 'snap_CA', 'snap_TX', 'snap_WI']\n",
        "# #TX_3\n",
        "# bad_2 = ['cat_id', 'snap_WI', 'weekend', 'enc_state_id_cat_id_mean_item_id',\n",
        "#          'enc_state_id_cat_id_std_item_id']\n",
        "# #WI_1\n",
        "# bad_3 = ['cat_id', 'price_nunique', 'snap_CA']\n",
        "# #CA_4\n",
        "# bad_4 = ['cat_id', 'price_nunique', 'snap_CA', 'snap_TX', 'snap_WI', 'quarter',\n",
        "#        'weekend', 'num_lags29', 'num_lags30', 'num_lags31', 'num_lags32',\n",
        "#        'num_lags33', 'num_lags34', 'num_lags35', 'num_lags36', 'num_lags37',\n",
        "#        'num_lags38', 'num_lags39', 'num_lags41']\n",
        "\n",
        "# bads = bad + bad_2 + bad_3 + bad_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PalejNcU7oia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#numpy.unique(ar, return_index=False, return_inverse=False, return_counts=False, axis=None)[source]\n",
        "bads_un, count_un = np.unique(bads, return_counts=True)\n",
        "temp = {}\n",
        "for i, j in zip(bads_un, count_un):\n",
        "  temp[i] = j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRmAxok69E7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d40b766-15c7-4f37-a7d8-2b8f918916d6"
      },
      "source": [
        "list_bads = pd.DataFrame([temp]).T\n",
        "list_bads[list_bads[0] > 1].index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['cat_id', 'price_nunique', 'snap_CA', 'snap_TX', 'snap_WI', 'weekend'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBnckrjXWvMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop = ['event_name_2', 'event_type_1', 'event_type_2', 'price_momentum',\n",
        "        'cat_id', 'price_nunique', 'snap_CA', 'snap_TX', 'snap_WI', 'weekend']\n",
        "keep_coll = [i for i in features if i not in drop]\n",
        "features = keep_coll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3uZy1Vd0W4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perm_features = ['item_id',\n",
        "                 'dept_id',\n",
        "                 'ewm_lags7',\n",
        "                 'num_lags_7_roll_7',\n",
        "                 'num_lags_7_roll_14', \n",
        "                 'num_lags_7_roll_30',\n",
        "                 'enc_store_id_mean_item_id',\n",
        "                 'dayofweek'\n",
        "                 ]\n",
        "features = perm_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TK31i5NGXFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqlMKgPcFj4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subsamp = np.array_split(list(df['id'].unique()), 10)\n",
        "score_features = pd.DataFrame()\n",
        "scores = []\n",
        "for sub in subsamp:\n",
        "  subsamp_df = df[df['id'].isin(sub)].reset_index(drop=True)\n",
        "  model = train_subsamp(subsamp_df, features)\n",
        "  scores.append(model.best_score['valid_0']['rmse'])\n",
        "  score_features = pd.concat([score_features, pd.Series(model.feature_importance())], axis =1)\n",
        "  pd.DataFrame(model.feature_importance(), index=features).plot(kind='bar',figsize=(17, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0LfuqsAjwJe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5fb4024-e37b-4f11-e977-1ecce886b5e5"
      },
      "source": [
        "\"\"\"\n",
        "Subsample:\n",
        "  -CA_2\n",
        "    ['event_name_2', 'event_type_1', 'event_type_2', 'price_momentum'] --> (1.7802324353191772, 0.45158946277682527)\n",
        "  -TX_3 --> (1.605701682659935, 0.4332082446979661)\n",
        "  -WI_1 --> (1.5142664096872367, 0.4108342572650494)\n",
        "Not subsample:\n",
        "  -CA_4 --> (1.317845, 0.015445123479134565)\n",
        "\n",
        "Subsample:\n",
        "  -CA_2\n",
        "    ['cat_id', 'price_nunique', 'snap_CA', 'snap_TX', 'snap_WI', 'weekend'] --> (1.7823305656292259, 0.45302598267327565)\n",
        "  -TX_3 --> (1.6078363699461182, 0.43318972019543384)\n",
        "  -WI_1 --> (1.517839978292082, 0.4119846665658397)\n",
        "Not subsample:\n",
        "  -CA_4 --> (1.3203650000000002, 0.014567340060167846)\n",
        "\n",
        "prom_features:\n",
        "  -CA_4 --> (1.3153707690346885, 0.3549353095401551)\n",
        "\"\"\"\n",
        "np.mean(scores), np.std(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.3153707690346885, 0.3549353095401551)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0P3dV66Y1BL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "86232818-f2ad-4f72-edbb-2e65b3cf1ae2"
      },
      "source": [
        "new_features = ['jan',\n",
        "                'feb',\n",
        "                'mar',\n",
        "                'apr',\n",
        "                'may',\n",
        "                'jun']\n",
        "                "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4473524758440748,\n",
              " 0.9656838925609528,\n",
              " 1.5552063894651775,\n",
              " 1.4446131082296554,\n",
              " 1.0496933013205834,\n",
              " 1.3079983472768146,\n",
              " 1.0788898776306532,\n",
              " 1.2061298215866436,\n",
              " 0.899996070932644,\n",
              " 0.7732966154654519]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYxIj35xqyYe",
        "colab_type": "text"
      },
      "source": [
        "###subsample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9Sl7dzkqx9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_features.index = features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd2f9kiOqx3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5740812f-2f14-4812-d05b-23ecf5e069fa"
      },
      "source": [
        "score_features.mean(axis = 1)[score_features.mean(axis = 1) < 50].index#score_features[1:].mean(axis =1).mean()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['enc_state_id_cat_id_mean_item_id', 'enc_state_id_cat_id_std_item_id'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkdCJeodqo8u",
        "colab_type": "text"
      },
      "source": [
        "###permutation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8yfgFt1a9Z1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "fec8487f-611d-4615-f366-ded852207276"
      },
      "source": [
        "def train_permutation(df, features):\n",
        "\n",
        "  train_mask = df.d <= (1913 -28)\n",
        "  val_mask = df.d > (1913 -28)\n",
        "  \n",
        "  train_data = lgb.Dataset(df[train_mask][features], \n",
        "                        label=df[train_mask]['sales'])  \n",
        "  train_data.save_binary('train_data.bin')\n",
        "  train_data = lgb.Dataset('train_data.bin')\n",
        "  val_data = lgb.Dataset(df[val_mask][features], \n",
        "                      label=df[val_mask]['sales'])\n",
        "  #-------------------------  \n",
        "  # X_test = df[test_mask][features]\n",
        "  # y_test=df[test_mask]['sales']\n",
        "  #-------------------------\n",
        "  X_test = df[val_mask][features]\n",
        "  y_test=df[val_mask]['sales']\n",
        "     \n",
        "  del df\n",
        "  gc.collect()\n",
        "  print('Start train lgbm')\n",
        "  estimator = lgb.train(lgb_params,\n",
        "                        train_data,\n",
        "                        valid_sets = [val_data],\n",
        "                        verbose_eval = 100,\n",
        "                        #early_stopping_rounds=50                        \n",
        "                        )\n",
        "  !rm '/content/train_data.bin'\n",
        "  del train_data, val_data#, estimator\n",
        "  gc.collect()\n",
        "  print('Ends')\n",
        "  print('Permutation\\n')\n",
        "  \n",
        "  pred = estimator.predict(X_test)\n",
        "  rmse = np.sqrt(np.mean(np.square(y_test - pred)))\n",
        "  print(f'Baseline  with lags RMSE: {rmse}')\n",
        "  for f in features:\n",
        "    temp_test = X_test.copy()\n",
        "\n",
        "    if temp_test[f].dtypes.name != 'category':\n",
        "          temp_test[f] = np.random.permutation(temp_test[f].values)    \n",
        "  \n",
        "    pred = estimator.predict(temp_test[features])\n",
        "    test_rmse = np.sqrt(np.mean(np.square(y_test - pred)))\n",
        "    print(f, np.round(test_rmse - rmse, 4)) \n",
        "\n",
        "train_permutation(df, features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start train lgbm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[100]\tvalid_0's rmse: 1.25485\n",
            "[200]\tvalid_0's rmse: 1.25299\n",
            "[300]\tvalid_0's rmse: 1.24464\n",
            "[400]\tvalid_0's rmse: 1.26053\n",
            "[500]\tvalid_0's rmse: 1.26232\n",
            "[600]\tvalid_0's rmse: 1.26683\n",
            "[700]\tvalid_0's rmse: 1.27396\n",
            "[800]\tvalid_0's rmse: 1.28039\n",
            "[900]\tvalid_0's rmse: 1.2883\n",
            "[1000]\tvalid_0's rmse: 1.28293\n",
            "[1100]\tvalid_0's rmse: 1.28189\n",
            "[1200]\tvalid_0's rmse: 1.27538\n",
            "[1300]\tvalid_0's rmse: 1.2755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCR2tkV24aUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Baseline  with lags RMSE: 1.2342131449390197\n",
        "item_id 0.0\n",
        "dept_id 0.0\n",
        "cat_id 0.0\n",
        "start_sell 0.031\n",
        "sell_price 0.0002\n",
        "price_max 0.0005\n",
        "price_min 0.0003\n",
        "price_std 0.0003\n",
        "price_mean 0.0006\n",
        "price_norm -0.0002\n",
        "price_nunique -0.0002\n",
        "item_nunique 0.0012\n",
        "price_momentum 0.0003\n",
        "price_momentum_m 0.0009\n",
        "price_momentum_y 0.0\n",
        "event_name_1 0.0\n",
        "event_type_1 0.0\n",
        "event_name_2 0.0\n",
        "event_type_2 0.0\n",
        "snap_CA 0.0\n",
        "snap_TX 0.0\n",
        "snap_WI 0.0\n",
        "day -0.0015\n",
        "month 0.0491\n",
        "quarter 0.002\n",
        "week 0.0125\n",
        "dayofweek 0.0097\n",
        "year 0.0\n",
        "weekend 0.0005\n",
        "sales_lag_28 0.0\n",
        "sales_lag_29 -0.0\n",
        "sales_lag_30 0.0005\n",
        "sales_lag_31 0.0005\n",
        "sales_lag_32 0.0004\n",
        "sales_lag_33 0.0005\n",
        "sales_lag_34 0.0002\n",
        "sales_lag_35 -0.0003\n",
        "sales_lag_36 0.0005\n",
        "sales_lag_37 0.0002\n",
        "sales_lag_38 0.0001\n",
        "sales_lag_39 0.0005\n",
        "sales_lag_40 0.0002\n",
        "sales_lag_41 -0.0001\n",
        "sales_lag_42 -0.0001\n",
        "rolling_mean_7 0.0008\n",
        "rolling_std_7 0.0008\n",
        "rolling_mean_14 0.0005\n",
        "rolling_std_14 0.0009\n",
        "rolling_mean_30 0.0005\n",
        "rolling_std_30 -0.0\n",
        "rolling_mean_60 0.0005\n",
        "rolling_std_60 0.0006\n",
        "rolling_mean_180 0.0016\n",
        "rolling_std_180 0.0006\n",
        "rolling_mean_tmp_1_7 0.2515\n",
        "rolling_mean_tmp_1_14 0.1663\n",
        "rolling_mean_tmp_1_30 0.0446\n",
        "rolling_mean_tmp_1_60 0.0034\n",
        "rolling_mean_tmp_7_7 0.0181\n",
        "rolling_mean_tmp_7_14 0.0032\n",
        "rolling_mean_tmp_7_30 0.0017\n",
        "rolling_mean_tmp_7_60 0.0006\n",
        "rolling_mean_tmp_14_7 0.0031\n",
        "rolling_mean_tmp_14_14 0.0016\n",
        "rolling_mean_tmp_14_30 0.0006\n",
        "rolling_mean_tmp_14_60 0.0007\n",
        "enc_item_id_mean -0.0002\n",
        "enc_item_id_std 0.0002\n",
        "enc_state_id_mean_item_id 0.0002\n",
        "enc_state_id_std_item_id 0.0001\n",
        "enc_store_id_mean_item_id 0.0045\n",
        "enc_store_id_std_item_id 0.0044\n",
        "enc_cat_id_mean_item_id -0.0\n",
        "enc_cat_id_std_item_id -0.0004\n",
        "enc_state_id_cat_id_mean_item_id -0.0001\n",
        "enc_state_id_cat_id_std_item_id -0.0007\n",
        "Close 0.0009\n",
        "Volume 0.0002\n",
        "Adj Close 0.0007\n",
        "ewm_lags7 0.041\n",
        "ewm_lags14 0.0006\n",
        "ewm_lags30 0.0004\n",
        "ewm_lags60 0.0003\n",
        "exp_lags7 0.0068\n",
        "exp_lags14 0.0026\n",
        "exp_lags30 0.0026\n",
        "exp_lags60 0.0094\n",
        "std_sells_month 0.0001\n",
        "var_sells_month 0.02\n",
        "mean_sells_month 0.1516\n",
        "jan 0.0195\n",
        "feb 0.0129\n",
        "mar 0.0411\n",
        "apr 0.172\n",
        "may 0.0009\n",
        "jun 0.003"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}